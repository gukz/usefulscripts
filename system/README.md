# 课程笔记
每个[课程地址](https://www.bilibili.com/video/BV1N741177F5?p=3)视频需要看3遍左右
1. 初略理解一下课程内容
2. 抓一下细节，跳着看课程内容
3. 将课程内容整理成笔记

# P1 [绪论] 操作系统的历史

# P2 [代码讲解] 应用眼中的操作系统；系统调用

# P3 [并发] 多处理器编程：从入门到放弃
- 并发的控制技术主要是在操作系统中研究的，操作系统是最早的并发系统。
- 线程的内存隔离地址空间的，但是操作系统中的对象是共享的。如标准输入、输出。 
- 并发的来源：进程会调用操作系统API。
> write(fd, buf, 1 TiB)([TiB宏](?))
> write的实现是操作系统的一部分，x86-64应用程序执行syscall后就进入操作系统执行，应用程序不可见，系统调用运行在处理器的高特权级，能访问硬件设备但有不能一直霸占处理器
> 允许write写到一半的时候，让另一个进程执行（让出系统资源的使用权）如另一个进程调用read(fd, buf, 512 Mib)读取同一个文件

## 概念 并发concurrency SegmentFalt
- 有一些事情可以同时发送，在计算机中表现为乱序执行
- 为了使CPU运行的更快，CPU可以不按照顺序执行指令，现代处理器（动态数据分析）
> 如果两条指令没有数据依赖关系，就让他们并行执行！
> 乱序执行（out-of-order）多处理器上指令执行的顺序可以不等价于指令顺序
- 每个线程都会分配一定大小的堆栈（8M），创建线程后仅仅是在内存中标记了一下，并没有实际将内存分配给相应线程，因此理论上可以创建很多线程 ?
    > 使用`pmap <pid>`来查看内存分配情况，可以看到如下输出：
    > 00007f76b7d0a000   8192K rw---   [ anon ]
    > 00007f76b7e8a000      4K -----   [ anon ]  # 多不同线程之间栈的guard，因此栈无论上衣或下衣都会SegmentFalt
    > 00007f76b7f2a000   8192K rw---   [ anon ]


## 一个例子理解: 多个执行流并发/并行执行，并且共享内存
- 两个执行流共享 __代码和全局变量__
- 线程之间指令的执行顺序是不确定的
    ```c
// 例子1，两个线程同时发生系统调用 write 会发生什么
// 不控制并发的情况下，第二次数据写入会覆盖第一次写入的数据，但是offset仍然顺序增加了，文件中出现了一部分完全没有写入数据


// 例子2，求和
#define n 100000000
long sum = 0;

void do_sum() { for (int i = 0; i < n; i ++) sum ++; }
void print() { printf("sum = %ld\n", sum) }
int main() {
    create(do_sum);
    create(do_sum);
    join(print);
}
// 结果：(编译器做了不同的优化，汇编代码完全不同)
-O0: 113863902
-O1: 100000000 // nop 循环 n; sum = sum + n
-O2: 200000000 // sum = sum + n

// 两个线程分别操作并打印两个全局变量
int x = 0, y = 0;
void thread_1() {
    [1] x = 1;
    [2] printf("y = %d\n", y);
}
void thread_2() {
    [3] y = 1;
    [4] printf("x = %d\n", x);
}
/* 执行结果：
x   y   per   order
0   0   0.2%  ???
0   1   82.3% 3-4-1-2
1   0   17.5% 1-2-3-4
1   1   0.0%  1-3-2-4 从来没有被执行，因为现代CPU如果发生cache miss会不按顺序执行指令
原因：
由于1，2和3，4分别操作了不同的变量，因此print语句和赋值语句的执行顺序被颠倒了
见下面的汇编代码
*/
    ```
```asm
movl $1, (x)    # x = 1, cache miss
                # 如果等这条指令执行完，会浪费大量时间（重新同步cache）
movl (y), %eax  # 只要x，y不是同一个变量，CPU就会立即执行这条指令（上一条指令会放入某个队列）
                # （此时y=0）
```
## 总结
代码的执行比我们想象的还要复杂 即便是 x = 1 赋值操作并发执行下也会有很多问题：
1. C代码由于编译器优化 -> 代码执行 __顺序__丧失
> 保证顺序使用
2. 二进制文件运行时，由于 __中断/并行__ -> __原子性__丧失
> 保证原子性 互斥 效果等同于：
> stop_the_world
> ...  // 执行临界区代码
> resume_the_word
3. 现代CPU会乱序执行指令 -> __可见性__的丧失
> 保证可见性 指令来帮忙 简化自C11 Memory Model
> 顺序指令 
> - fences(lfence,sfence,mfence,...)
> 原子指令 
> - x86-family: lock prefix(lock xchg,...)
> - riscv/mips: load-reservation/store-condictional(mip)
## 结论
1. 不要自作主张写“聪明”的并发程序
> [这篇](./Ad_Hoc_Synchronization_Considered_Harmful.pdf)论文讲述了很多无锁、直接使用变量的方式实现多线程同步，并且证明了这些方案是错误的或有性能问题的
2. 老老实实使用久经考验的API?，写出读得懂的、说明得了正确性的代码
## 引申
- 并发算法
> 并发算法是非常有趣（很难）的研究问题
> 《多处理器编程的艺术》世界上最好的并发编程教科书

## 参考
1. [《计算机体系结构 量化研究方法》](?) 对于现代处理器的机制做了比较清楚的阐释


# P4 [并发] 理解并发程序的执行；状态机视角下的程序执行
- 串行程序的状态机模型（工具）
- 状态机模型的应用
- 并发程序的状态机模型
- 理解并发软件的执行
- 把线程想象成人、把共享内存想象成物理世界
## 有限状态机
- 程序 = 有限状态机 = 有向图
> 状态：寄存器、内存状态
## Peterson算法的正确性证明



# P5 [并发] 并发控制（1）：线程的互斥

## 互斥：直观理解
- 希望不被别人打断，如使用厕所的一间包厢。
- lock/unlockAPI
```c
typedef struct {
...
} lock_t
void lock(lock_t *lk);
void unlock(lock_t *lk);
```
- 一把排他锁
    > 在任何线程调度下，若某个线程持有锁（lock(lk)返回且未释放），则任何其他线程的lock(lk)都不能返回
- 状态机视角
    > lock 返回会进入“locked”状态，unlock会清除该状态
    > 初始状态s0不能到达两个线程都进入locked的状态
## 互斥锁作用
- 由锁锁定的代码完全不能并发，挽回了并发编程时， __原子性，顺序性，可见性__

# P6 [代码讲解] 硬件眼中的操作系统：硬件初始化和操作系统的加载
